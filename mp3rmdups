#!/usr/bin/env python3
"""Removes duplicate mp3's from the specified directory path.

Usage: mp3rmdups [<path>...]
Defaults to current directory.
"""

import sys
from collections import namedtuple, defaultdict
from hashlib import md5
from os.path import getmtime
from pathlib import Path
from pprint import pprint
from string import digits

# When sorted, these tuples come out with the earliest file first.
musfilestuff = namedtuple('musfilestuff', ['mtime', 'name'])


def filename_trackno_hash(filename):
    """Return the track number specified in the file name."""
    try:
        if filename[0] in digits:
            endix = filename.index(' ')
            return filename[0:endix]
        else:
            return filename
    except (IndexError, ValueError):
        return filename


def rm_dup_mp3s(pathspec, groupby='md5_hexdigest'):
    """Remove all duplicate mp3's in pathspec except the earliest, and return saved filenames.

    pathspec is a Path object defining the directory to be processed.
    groupby is a string defining how files are grouped. It can be any of the following:
    md5_hexdigest:    files are grouped if their MD5 hashes are the same. (Default)
    filename_trackno: files are grouped if the track numbers in their filenames are the same.
    all_files:        all files are grouped together; only the oldest will remain.
    """
    hashes = defaultdict(list)
    for f in pathspec.glob('*.mp3'):
        m = musfilestuff(mtime=getmtime(f), name=f.resolve())
        if groupby == 'md5_hexdigest':
            with f.open('rb') as fbin:
                md5hash = md5(fbin.read()).hexdigest()
                hashes[md5hash].append(m)
        elif groupby == 'filename_trackno':
            hashes[filename_trackno_hash(f.name)].append(m)
        elif groupby == 'all_files':
            hashes[''].append(m)
        else:
            # In all other cases, files are individually grouped, preserving them all.
            hashes[f.name].append(m)

    # Remove all but the earliest music file from each file group.
    saved = list()
    for h in hashes.keys():
        filelist = list(hashes[h])
        filelist.sort()
        m1 = filelist.pop(0)
        saved.append(m1)
        for mz in filelist:
            Path(mz.name).unlink()

    # Print out the saved files. There can be duplicate files that vary in
    # minor details.
    savedfilenames = [m.name for m in saved]
    savedfilenames.sort()
    return savedfilenames


def main(pathlist):
    """Remove duplicate MP3s from each directory"""
    if not pathlist:
        pathlist = list('.')
    for pname in pathlist:
        p = Path(pname)
        if p.is_dir():
            savedmp3 = rm_dup_mp3s(p)
            print(f"[{p.resolve().name}]")
            for f in savedmp3:
                print(f)
        else:
            print(f"(Skipping {p}: not a directory)")
        print("")

if __name__ == '__main__':
    main(sys.argv[1:])

#---+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0
# TODO: Look into virtual env for this project.
# TODO: Show a progress indicator while hashing music files, similar to how fdupes works.
# TODO: Provide an option to compare files with the same track number in filename. How can we do this?
# TODO: Consider the following design for stripping duplicates:
#           * Keep only the earliest file in the MD5-hashdigest comparisons.
#           * Then compare files with the same track number. (For a while in 2013-14, GMM would modify the MP3s.)
#           * Keep the earliest of these if they're the same song.
#       NOTE: Make backups before running this scheme.
# TODO: Use argparse, or DocOpt, to define command-line switches.
#---+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0----+----0
